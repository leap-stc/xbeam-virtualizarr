name: Deploy Recipes to Google Dataflow

env:
  JOB_NAME: ${{ github.event.inputs.recipe_id }}-${{ github.run_id }}-${{ github.run_attempt }}

on:
  workflow_dispatch:
    inputs:
      recipe_id:
        description: 'The id of a single recipe to submit to Dataflow'
        required: true
        default: 'test-job'

jobs:
  deploy-recipes:
    runs-on: ubuntu-latest
    steps:


      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Setup python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: "Authenticate to Google Cloud"
        id: "auth"
        uses: "google-github-actions/auth@v2"
        with:
          credentials_json: "${{ secrets.LEAP_BAKERY_SERVICE_ACCOUNT }}"

      - name: "Install deps"
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e .[test]
          python -m pip install apache-beam[gcp]



      - name : "Deploy Beam pipeline"
        run: |
         python xbeam_virtualizarr/recipe.py \
          --runner DataflowRunner \
          --requirements_file requirements.txt  \
          --project leap-pangeo \
          --job_name $JOB_NAME \
          --region us-central1 \
          --machine_type t2d-standard-16	 \
          --disk_size_gb 50 \
          --max_num_workers 50 \
          --temp_location gs://leap-scratch/norlandrhagen/dataflow_temp/temp/ \
          --staging_location gs://leap-scratch/norlandrhagen/dataflow_temp/staging/
